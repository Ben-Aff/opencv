图像由像素点构成
每个像素点都有值0-255，表示亮度，值越大亮度越大
图像由R、G、B三个通道构成，黑白图只有一个通道（Opencv中的组成形式是BGR）
因此图像通常由三个矩阵表示
位深度：32(支持透明度)、24(不支持透明通道)
图像的分辨率表示宽和高的像素值
opencv不支持透明度的读取，都会统一读取为RGB三个通道的
图像色彩模式
位图模式
位图模式是图像中最基本的格式，图像只有黑色和白色像素，是色彩模式中占有空间最小的，同样也叫做黑白图，它包含的信息量最少，无法包含图像中的细节，相当于只有0或者1
一副彩色图如果要转换成黑白模式，则一般不能直接转换，需要首先将图像转换成灰度模式
灰度模式
灰度模式即使用单一色调来表示图像，与位图模式不同，不像位图只有0和1，使用256级的灰度来表示图像，一个像素相当于占用8为一个字节，每个像素值使用0到255的亮度值代表，其中0为黑色，255为白色，相当于从黑->灰->白的过度，通常我们所说的黑白照片就是这种模式，与位图模式相比，能表现出一定的细节，占用空间也比位图模式较大
RGB模式
RGB模式为我们经常见到的，被称为真色彩。RGB模式的图像有3个颜色通道，分布为红（Red）,绿（Green）和蓝（Bule），每个都占用8位一个字节来表示颜色信息，这样每个颜色的取值范围为0~255，那么就三种颜色就可以有多种组合，
当三种基色的值相等是，表现出为灰色，三种颜色都为255即为白色，三种颜色都为0，即为黑色
RGB模式的图像占用空间要比位图，灰度图都要大，但表现出的细节更加明显













ROI（regionofinterest），感兴趣区域。
机器视觉、图像处理中，从被处理的图像以方框、圆、椭圆、不规则多边形等方式勾勒出需要处理的区域，称为感兴趣区域，又称为ROI。
在图像处理领域，感兴趣区域(ROI)是从图像中选择的一个图像区域，这个区域可以是点、线、面不规则的形状，通常用来作为图像分类的样本、掩膜、裁剪区等
作用:ROI区域是你的图像分析所关注的重点。圈定该区域以便进行进一步处理。使用ROI可以减少处理时间，增加精度。
获取方式:ROI是图像的一部分，它通过在图像上选择或使用诸如通过算子设定阈值(thresholding)或者从其他文件(如矢量>转换获得等方法生成。




opencv中的数据类型








图像的三种属性
图像形状(shape)、像素大小(size)、图像类型(dtype)
（1）shape
通过shape关键字获取图像的形状，返回包含行数、列数、通道数的元组。其中灰度图像返回行数和列数，彩色图像返回行数、列数和通道数。
（2）size
通过size关键字获取图像的像素数目，其中灰度图像返回行数×列数，彩色图像返回行数×列数×通道数。
（3）dtype
通过dtype关键字获取图像的数据类型，通常返回uint8。










#读取图片与加载图片
img=cv2.imread("参数一",参数二)
参数一：图片位置
参数二：1：以彩色模式加载图像，任何图像的透明度都将被忽略。这是默认参数。
       0：以灰度模式加载图像
cv2.imshow("参数一",参数二)
参数一：显示窗口的名字
参数二：图像名
cv2.waitKey(0)
键盘绑定函数，只有一个参数delay，表示等待的毫秒数，看键盘是否有输入，0表示无期限等待键盘输入，可以任意键结束，大于0表示等待delay毫秒；参数小于0表示等待键盘单击。
用cv.waitKey()给图像绘制留下时间，否则窗口会出现无响应情况，并且图像无法显示出来。
cv2.destroyAllWindows()
释放所有窗口



#保存图片
cv2.imwrite("参数一",参数二)
参数一：指定要保存的位置和图片的名字
参数二：图像名
#图片的色彩转换空间转换
OpenCV中有150多种颜色空间转换方法。最广泛使用的转换方法有三种，BGR-RGB、BGR-Gray和BGR-HSV。
cv.cvtColor(参数一，参数二)
参数一：图像名
参数二：图像转换方法
cv.COLOR_BGR2RGB : BGR to RGB
cv.COLOR_BGR2GRAY : BGR to Gray
cv.COLOR_BGR2HSV: BGR to HSV
#图像对象的创建与赋值
opencv中的图像都是numpy对象
#图像的形状
image.shape


#创建空白图像
(1)参数一=np.zeros((h，w，c),dtype=np.uint8)
参数一：空白图像名，常用black、emptyImage
(2)图像名=np.zeros_like(参数一)
参数一：要创立相同尺寸的图片变量名


#图像局部区域显示
1.ROI=图像名[](python列表切片操作)
2.空白图像[]=ROI

#创建窗口
cv2.namedWindow(参数一,参数二)
参数一：将显示图像/视频的窗口的名称
参数二：表示窗口大小是自动设置还是可调整。


#图像的拷贝操作
两种方式
1.使用numpy进行操作：图像1=np.copy(图像2)
2.直接用：图像1=图像2
注意：使用numpy的效果会更好


#opencv中的自带颜色表
applyColorMap(输入图像、输出图像、颜色表)
颜色表：





#像素处理
(1)OpenCV中读取图像的像素值可以直接通过遍历图像的位置实现，如果是灰度图像则返回其灰度值，如果是彩色图像则返回蓝色（B）、绿色（G）、红色（G）三个分量值。其示例如下：
灰度图像：返回值 = 图像[位置参数]
示例：test=img[88,42]
彩色图像：返回值 = 图像[位置元素, 0 | 1 | 2 ]获取BGR三个通道像素
示例：blue=img[88,142,0] green=img[88,142,1] red=img[88,142,2]
(2)NumPy像素处理读取像素和修改像素的方法
NumPy读取像素调用item()函数实现，修改像素调用itemset()实现，调用方式如下：
读取像素：
返回值 = 图像.item(位置参数)
例如：blue = img.item(78, 100, 0)
修改像素：
图像.itemset(位置, 新值)
例如：img.itemset((88,99), 255)


















#图像的四则运算
OpenCV提供函数把两幅图像相加，或通过numpy操作添加两个图像，如res = img1 + img2。两个图像应该具有相同的大小和类型，或者第二个图像可以是标量值。
加法：cv.add(图像1，图像2/区域像素值)(增加图片的像素值来使得图片变亮或直接将两幅图片相加融合)

注意，当两幅图像的像素值相加结果小于等于255时，则输出图像直接赋值该结果，如120+48赋值为168；如果相加值大于255，则输出图像的像素结果设置为255，如(255+64) 赋值为255



减法：cv.substract(图像1，图像2/区域像素值)(减少图片的像素值来使得图片变暗或直接将两幅图片相减)
乘法：cv.multiply(图像1，区域像素值倍数)(增加图片的对比度)
除法：cv.divide(图像1，区域像素值倍数)(减少图片的对比度)
注意：使用opencv进行操作，效果会更好












#图像融合
本质也是加法，但在图像加法的基础上给两幅图像增加了不同的权重系数和亮度调节量。图像融合的计算公式如下：
g(x) = (1−α)f0(x) + αf1(x)+γ(亮度调节量)
cv.addWeighted(图片1,1的权重,图片2,2的权重,γ)




#图像中像素的逻辑运算
或操作
cv2.bitwise_or(图像1，图像2)，对两张图像的像素值取或操作
与操作&
cv2.bitwise_and(图像1，图像2)，对两张图像的像素值取与操作
非操作
图像非运算就是图像的像素反色处理，它将原始图像的黑色像素点转换为白色像素点，白色像素点则转换为黑色像素点
cv2.bitwise_not(图像1，图像2)
注意：逻辑运算要求两个图像的形状完全相同
00001001，图像1的像素值
00001110，图像2的像素值
与操作00001000，都变成黑，取反操作11110111
或操作00001111，都变成白，取反操作11110000

























#图像的通道分离与合并
(1)使用python中的切片操作
(2)cv.split()和cv.merge()的配合
cv2.split(参数一[,参数二])将3通道BGR彩色图像分离为B、G、R 单通道图像(一个三维数组)。
参数一：图像或nparray多维数组
参数二：指定的分拆通道（可选）
mv=split(m[, mv])
–m表示输入的多通道数组
–mv表示输出的数组或vector容器
merge()函数
该函数是split()函数的逆向操作，将多个数组合成一个通道的数组，从而实现图像通道的合并，其函数原型如下：
dst=merge(mv[, dst])
–mv表示输入的需要合并的数组，所有矩阵必须有相同的大小和深度
–dst表示输出具有与mv相同大小和深度的数组
注意：使用python中的切片操作取得的效果更好





#图像几何变换
图像几何变换不改变图像的像素值，在图像平面上进行像素变换。
作用:适当的几何变换可以最大程度地消除由于成像角度、透视关系乃至镜头自身原因所造成的几何失真所产生的负面影响。
几何变换常常作为图像处理应用的预处理步骤，是图像归一化的核心工作之一。
一个几何变换需要两部分运算：
空间变换：包括平移、缩放、旋转和正平行投影等，需要用它来表示输出图像与输入图像之间的像素映射关系。
灰度插值算法：按照这种变换关系进行计算，输出图像的像素可能被映射到输入图像的非整数坐标上。
图像几何变换在变换过程中会建立一种原图像像素与变换后图像像素之间的映射关系，通过这种关系，能够从一方的像素计算出另一方的像素的坐标位置。
通常将图像坐标映射到输出的过程称作向前映射，反之，将输出图像映射到输入的过程称作向后映射。向后映射在实践中使用较多，原因是能够避免使用向前映射中出现映射不完全和映射重叠的问题。
对于数字图像而言，像素的坐标是离散型非负整数，但是在进行变换的过程中有可能产生浮点坐标值。这在图像处理中是一个无效的坐标。为了解决这个问题需要用到插值算法。常见算法如下：
最近邻插值
双线性插值
双立方插值
图像变换是建立在矩阵运算基础上，通过矩阵运算可以很快找到对应关系。图像几何变换，包括图形平移、图像缩放、图像旋转、图像镜像、图像仿射、图像透视等。


(1)图像平移
平移的矩阵形式为:

式子中，矩阵称为平移变换矩阵或因子，△x和△y称为平移量。图像平移首先定义平移矩阵M，再调用warpAffine()函数实现平移
M = np.float32([[1, 0, x], [0, 1, y]])
– M表示平移矩阵，其中x表示水平平移量，y表示垂直平移量
shifted = cv2.warpAffine(src, M, (dsize))
– src表示原始图像
– M表示平移矩阵
– dsize表示变换后的输出图像的尺寸大小






(2)图像缩放
图像缩放（image scaling）是指对数字图像的大小进行调整的过程。图像缩放主要调用resize()函数实现，函数原型如下：
result = cv2.resize(src, (dsize))
– src表示原始图像
– dsize表示图像缩放的大小
或: result = cv2.resize(src, fx=,fy=)
– src表示原始图像
– fx表示图像x轴方向缩放大小的倍数
– fy表示图像y轴方向缩放大小的倍数
常见的图像缩放两种方式如下所示，第一种方式是将原图像设置为(160, 160)像素大小，第二种方式是将原始图像缩小为0.5倍。
result = cv2.resize(src,(160,160))
result = cv2.resize(src,fx=0.5, fy=0.5)


(3) 图像旋转

图像旋转是指图像以某一点为中心旋转一定的角度，形成一幅新的图像的过程。图像旋转变换会有一个旋转中心，这个旋转中心一般为图像的中心，旋转之后图像的大小一般会发生改变。

图像旋转变换主要调用getRotationMatrix2D()函数和warpAffine()函数实现，绕图像的中心旋转，函数原型如下：

M = cv2.getRotationMatrix2D(center, angle, scale)
– center表示旋转中心点，通常设置为(cols/2, rows/2)
– angle表示旋转角度，正值表示逆时针旋转，坐标原点被定为左上角
– scale表示比例因子
rotated = cv2.warpAffine(src, M, (cols, rows))
– src表示原始图像
– M表示旋转参数，即getRotationMatrix2D()函数定义的结果
– (cols, rows)表示原始图像的宽度和高度


(4)图像镜像变换
Python中主要调用OpenCV的flip()函数实现图像镜像变换，函数原型如下：

dst = cv2.flip(src, flipCode)
– src表示原始图像
– flipCode表示翻转方向，如果flipCode为0，则以X轴为对称轴翻转，如果fliipCode>0则以Y轴为对称轴翻转，如果flipCode<0则在X轴、Y轴方向同时翻转。




(5)图像仿射变换
图像的旋转加上拉升就是图像仿射变换，仿射变换需要一个M矩阵实现，但是由于仿射变换比较复杂，很难找到这个M矩阵，OpenCV提供了根据变换前后三个点的对应关系来自动求解M的函数cv2.getAffineTransform(pos1,pos2)：
cv2.getAffineTransform(pos1,pos2)
cv2.warpAffine(src, M, (cols, rows))
– src表示原始图像
– M表示仿射变换矩阵
– (rows,cols)表示变换后的图像大小，rows表示行数，cols表示列数
其中pos1和pos2表示变换前后的对应位置关系，输出的结果为仿射矩阵M，接着使用函数cv2.warpAffine()实现图像仿射变换。图7-4是仿射变换的前后效果图。

(6)图像透视
图像透视变换（Perspective Transformation）的本质是将图像投影到一个新的视平面，同理OpenCV通过函数cv2.getPerspectiveTransform(pos1,pos2)构造矩阵M，其中pos1和pos2分别表示变换前后的4个点对应位置。得到M后在通过函数cv2.warpPerspective(src,M,(cols,rows))进行透视变换。
图像透视变换的函数原型如下：
M = cv2.getPerspectiveTransform(pos1, pos2)
– pos1表示透视变换前的4个点对应位置
– pos2表示透视变换后的4个点对应位置
cv2.warpPerspective(src,M,(cols,rows))
– src表示原始图像
– M表示透视变换矩阵
– (rows,cols)表示变换后的图像大小，rows表示行数，cols表示列数











#图像量化处理
量化（Quantization）旨在将图像像素点对应亮度的连续变化区间转换为单个特定值的过程，即将原始灰度图像的空间坐标幅度值离散化.
量化等级越多，图像层次越丰富，灰度分辨率越高，图像的质量也越好；量化等级越少，图像层次欠丰富，灰度分辨率越低，会出现图像轮廓分层的现象，降低了图像的质量。
如果量化等级为2，则将使用两种灰度级表示原始图片的像素（0-255），灰度值小于128的取0，大于等于128的取128；
如果量化等级为4，则将使用四种灰度级表示原始图片的像素，新图像将分层为四种颜色，0-64区间取0，64-128区间取64，128-192区间取128，192-255区间取192。
#opencv中的量化处理：
建立一张临时图片，接着循环遍历原始图像中所有像素点，判断每个像素点应该属于的量化等级，最后将临时图像显示。
#K-Means聚类实现量化处理
除了通过对像素进行统计比较量化处理，还可以根据像素之间的相似性进行聚类处理。K-Means聚类算法的量化处理过程能够将彩色图像RGB像素点进行颜色分割和颜色量化。
K-Means聚类算法的原理流程：
第一步：确定K值，聚类成K个类簇。
第二步：从数据中随机选择（或按照某种方式）K个数据点作为初始分类的中心。
第三步：分别计算数据中每个点到每个中心的距离，将每个点划分到离中心最近的类中
第四步：当每个中心都划分了一些点后，取每个类的均值，选出新的中心。
第五步：比较新的中心和之前的中心，如果新的中心和之前的中心之间的距离小于某阈值，或迭代次数超过某阈值，认为聚类已经收敛，终止。
第六步：否则继续迭代执行第三到五步，直到第五步满足。

cv2.kmeans(data, 聚类个数,criteria, 10, flags)
data:  需要分类数据，最好是np.float32的数据，每个特征放一列。
criteria：迭代停止的模式选择，这是一个含有三个元素的元组型数。格式为（type, max_iter, epsilon）其中，type有如下模式：
    cv2.TERM_CRITERIA_EPS ：精确度（误差）满足epsilon，则停止。
    cv2.TERM_CRITERIA_MAX_ITER：迭代次数超过max_iter，则停止。
    cv2.TERM_CRITERIA_EPS+cv2.TERM_CRITERIA_MAX_ITER：两者结合，满足任意一个结束。
flags：初始中心选择，可选以下两种：

cv2.KMEANS_PP_CENTERS：使用kmeans++算法的中心初始化算法，即初始中心的选择使眼色相差最大.
cv2.KMEANS_RANDOM_CENTERS：每次随机选择初始中心








#图像采样处理
图像采样（Image Sampling）处理是将一幅连续图像在空间上分割成M×N个网格，每个网格用一个亮度值或灰度值来表示，其示意图如图9-1所示。








图像采样的间隔越大，所得图像像素数越少，空间分辨率越低，图像质量越差，甚至出现马赛克效应；相反，图像采样的间隔越小，所得图像像素数越多，空间分辨率越高，图像质量越好，但数据量会相应的增大。图9-2展示了不同采样间隔的“Lena”图，其中图(a)为原始图像，图(b)为128×128的图像采样效果，图©为64×64的图像采样效果，图(d)为32×32的图像采样效果，图(e)为16×16的图像采样效果，图(f)为8×8的图像采样效果[1-3]。


图像采样的间隔越大，所得图像像素数越少，空间分辨率越低，图像质量越差，甚至出现马赛克效应；
相反，图像采样的间隔越小，所得图像像素数越多，空间分辨率越高，图像质量越好，但数据量会相应的增大。
Python图像采样处理：其核心流程是建立一张临时图片，设置需要采样的区域大小（如16×16），接着循环遍历原始图像中所有像素点，采样区域内的像素点赋值相同（如左上角像素点的灰度值），最终实现图像采样处理。










